{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---\n",
        "\n",
        "# Brain Tumor Segmentation with U-Net ðŸ§©\n",
        "\n",
        "**Objective**:\n",
        "Develop and evaluate a resource-efficient U-Net for delineating brain tumor subregions from multi-modal MRI.\n",
        "\n",
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "_kl_WNgO5RaT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 1. Setup ðŸ“¦\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "betb6FumJ_yK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Management\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Data Visualization\n",
        "from matplotlib.colors import ListedColormap\n",
        "import matplotlib.colors as mcolors\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Computational Modules\n",
        "import math\n",
        "from scipy.stats import norm, zscore\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
        "\n",
        "# Deep Learning Frameworks\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Utils\n",
        "from collections import defaultdict\n",
        "import h5py\n",
        "from google.colab import drive\n",
        "from IPython.display import display, HTML, IFrame, Image\n",
        "import os\n",
        "from pathlib import Path\n",
        "import random\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Settings\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('mode.chained_assignment', None)\n",
        "sns.set_style('darkgrid', {'grid.color':'0.9','xtick.bottom':True,'ytick.left':True})\n"
      ],
      "metadata": {
        "id": "Z4L1DiE45Tk4"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 2. Data Access ðŸ“‚\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "-q5A4-B0tL6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define project root\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8QbkH2Uh5KG",
        "outputId": "2bf9eb1b-4802-4153-d438-8c3237d1f34c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define file paths relative to drive structure\n",
        "data_path = '/content/drive/MyDrive/BraTS_Data/BraTS2020_training_data/content/data'\n",
        "meta_data_path = '/content/drive/MyDrive/BraTS_Data/BraTS2020_training_data/content/data/meta_data.csv'\n",
        "name_mapping_path = '/content/drive/MyDrive/BraTS_Data/BraTS2020_training_data/content/data/name_mapping.csv'\n",
        "survival_info_path = '/content/drive/MyDrive/BraTS_Data/BraTS2020_training_data/content/data/survival_info.csv'\n",
        "slice_paths = sorted(glob.glob(os.path.join(data_path, '*.h5')))  # get all .h5 files"
      ],
      "metadata": {
        "id": "BlMZmYFKKpm-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSVs into local dataframes\n",
        "meta_data_df = pd.read_csv(meta_data_path)\n",
        "name_mapping_df = pd.read_csv(name_mapping_path)\n",
        "survival_info_df = pd.read_csv(survival_info_path)"
      ],
      "metadata": {
        "id": "WGJPAwgftX92"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### TO BE EXECUTED BEFORE TRAINING FOR FULL DATASET ###\n",
        "### Copy dataset locally and use instead for faster access ###\n",
        "\n",
        "# !cp -r /content/drive/MyDrive/BraTS_Data /content/\n",
        "# data_path = '/content/BraTS_Data/BraTS2020_training_data/content/data'\n",
        "# slice_paths = sorted(glob.glob(os.path.join(data_path, '*.h5')))"
      ],
      "metadata": {
        "id": "iaD5vIEuVS9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 3. Model Prerequisites âš™ï¸\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "zSyoNkEttb4e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **3a. Split imaging data into training and validation sets.**"
      ],
      "metadata": {
        "id": "FEN5fz-ExwwB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this v1 (baseline model), only a limited set of MRI volumes will be used due to runtime trouble on free-tier Colab. Once an entire workflow is established, a more fleshed-out splitting will take place for future versions."
      ],
      "metadata": {
        "id": "C45gjdJeC40x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract random patient/volume IDs for baseline model\n",
        "random.seed(42)\n",
        "selected_patients = random.sample(range(0, 368), 4)\n",
        "print('Randomly selected patient IDs: ', selected_patients)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAFyKiC39SuP",
        "outputId": "53113d33-e78b-43a5-8961-b07510d5fcab"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Randomly selected patient IDs:  [327, 57, 12, 140]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert numeric IDs into corresponding filename prefixes\n",
        "selected_prefixes = [f'volume_{pid}_' for pid in selected_patients]\n",
        "selected_prefixes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1oNS6889vkx",
        "outputId": "250ddf3d-dc17-41ef-e104-e71e1b432179"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['volume_327_', 'volume_57_', 'volume_12_', 'volume_140_']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect all slices belonging to selected patients\n",
        "selected_slice_paths = [\n",
        "    path for path in slice_paths\n",
        "    if any(prefix in os.path.basename(path) for prefix in selected_prefixes)\n",
        "]\n",
        "print('Total selected slices: ', len(selected_slice_paths))\n",
        "# selected_slice_paths"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oXsjqMb-cBk",
        "outputId": "c17cd867-4eb1-4582-b3bb-7b5b09642008"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total selected slices:  620\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy selected slices to local runtime (for faster I/O during training)\n",
        "local_data_path = '/content/baseline_data'\n",
        "os.makedirs(local_data_path, exist_ok=True)\n",
        "for path in selected_slice_paths:\n",
        "    filename = os.path.basename(path)\n",
        "    !cp '{path}' '{local_data_path}/{filename}'"
      ],
      "metadata": {
        "id": "18lKEuic-sOR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rebuild slice list from local directory\n",
        "local_slice_paths = sorted(glob.glob(os.path.join(local_data_path, '*.h5')))\n",
        "print('Local slice count: ', len(local_slice_paths))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lfDSCaB-5pR",
        "outputId": "8290b2ec-5d9c-4eb7-f162-79907ea1caf6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Local slice count:  620\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group slices by patient (patient-level split)\n",
        "patient_to_slices = defaultdict(list)\n",
        "for path in local_slice_paths:\n",
        "    filename = os.path.basename(path)\n",
        "    patient_id = filename.split('_slice')[0]\n",
        "    patient_to_slices[patient_id].append(path)\n",
        "print(f'Patients found locally: {list(patient_to_slices.keys())}')"
      ],
      "metadata": {
        "id": "yL8GWqdXp1zm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f600a44f-6739-42dc-e4e7-cc3e3ea775f4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patients found locally: ['volume_12', 'volume_140', 'volume_327', 'volume_57']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Seperate train and validation patients\n",
        "patient_ids = list(patient_to_slices.keys())\n",
        "\n",
        "train_patients = ['volume_' + str(i) for i in selected_patients[:3]]\n",
        "val_patients = ['volume_' + str(i) for i in selected_patients[3:]]\n",
        "\n",
        "print('Train patients:', train_patients)\n",
        "print('Val patient:', val_patients)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRwvyvDPt1Qb",
        "outputId": "e62480e9-82da-44ee-e3e0-1060918cc11a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train patients: ['volume_327', 'volume_57', 'volume_12']\n",
            "Val patient: ['volume_140']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate train and validation slice paths\n",
        "train_paths = []\n",
        "val_paths = []\n",
        "\n",
        "for pid in train_patients:\n",
        "    train_paths.extend(patient_to_slices[pid])\n",
        "for pid in val_patients:\n",
        "    val_paths.extend(patient_to_slices[pid])\n",
        "\n",
        "print('Train slices:', len(train_paths))\n",
        "print('Val slices:', len(val_paths))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AFCE3bIt1Sh",
        "outputId": "79f90df8-60ea-4304-b317-515dcbb50e49"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train slices: 465\n",
            "Val slices: 155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Patient-Level Subset Selection and Split**\n",
        "\n",
        "To keep training within runtime limits, a small baseline subset was created by randomly selecting four patients (seed = 42). All slices belonging to these patients were identified and copied locally to the Colab runtime to ensure faster disk access during training.\n",
        "\n",
        "A deterministic 3:1 patient-level split was then applied. The split is performed at the patient level (not slice level) to prevent data leakage, ensuring that no slices from the same volume appear in both sets.\n",
        "\n",
        "This setup keeps the experiment lightweight while preserving proper evaluation structure."
      ],
      "metadata": {
        "id": "fjOSZdahNNer"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **3b. Format and standardize slices via PyTorch Dataset.**"
      ],
      "metadata": {
        "id": "UMeBiPnZIB3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BraTSDataset(Dataset):\n",
        "    \"\"\"\n",
        "    PyTorch Dataset for loading 2D BraTS slices stored as .h5 files.\n",
        "\n",
        "    Each file contains:\n",
        "        - image: (H, W, 4)\n",
        "              MRI modalities in order: [T1, T1Gd, T2, T2-FLAIR]\n",
        "        - mask:  (H, W, 3)\n",
        "              Binary tumor subregions: [NEC/NET, ED, ET]\n",
        "\n",
        "    Output format:\n",
        "        - image tensor: (4, H, W), float32\n",
        "        - mask tensor:  (3, H, W), float32\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, slice_paths):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            slice_paths (list): List of file paths to .h5 slice files.\n",
        "        \"\"\"\n",
        "        self.slice_paths = slice_paths\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns total number of slices and enables use with PyTorch DataLoader.\n",
        "        \"\"\"\n",
        "        return len(self.slice_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Loads and processes a single slice from disk.\n",
        "\n",
        "        Steps:\n",
        "            1. Load image + mask from disk (lazy loading)\n",
        "            2. Convert to float32 (memory + GPU compatible)\n",
        "            3. Apply per-slice, per-modality z-score normalization\n",
        "            3. Rearrange to channel-first format (C, H, W) for PyTorch\n",
        "            4. Convert to torch.Tensor\n",
        "        \"\"\"\n",
        "\n",
        "        file_path = self.slice_paths[idx]\n",
        "\n",
        "        # Load slice from disk (lazy loading; no full dataset in memory)\n",
        "        with h5py.File(file_path, 'r') as file:\n",
        "            image = file['image'][:]   # Shape: (H, W, 4)\n",
        "            mask  = file['mask'][:]    # Shape: (H, W, 3)\n",
        "\n",
        "        # Ensure correct dtype for training (convert to float32)\n",
        "        image = image.astype(np.float32)\n",
        "        mask  = mask.astype(np.float32)  # Also converted for loss computation; Binary values for each tumor subregion\n",
        "\n",
        "        # Per-slice & per-modality z-score normalization to standardize intensity dist. independently for each MRI modality channel\n",
        "        for c in range(image.shape[-1]):\n",
        "            channel = image[:, :, c]\n",
        "            mean = channel.mean()\n",
        "            std = channel.std()\n",
        "            if std > 0:\n",
        "                image[:, :, c] = (channel - mean) / std  # Improves optimization stability and handles inter-patient intensity variation\n",
        "            else:\n",
        "                image[:, :, c] = channel - mean  # Avoid division by zero if std=0\n",
        "\n",
        "        # Convert to channel-first format (C, H, W) (required for PyTorch Conv2D layers)\n",
        "        image = np.transpose(image, (2, 0, 1))  # (4, H, W)\n",
        "        mask  = np.transpose(mask, (2, 0, 1))   # (3, H, W)\n",
        "\n",
        "        # Convert numpy arrays to torch tensors\n",
        "        image_tensor = torch.from_numpy(image)\n",
        "        mask_tensor  = torch.from_numpy(mask)\n",
        "\n",
        "        return image_tensor, mask_tensor"
      ],
      "metadata": {
        "id": "wXfnBtvwIK1G"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement processing steps onto train and validation sets\n",
        "train_dataset = BraTSDataset(train_paths)\n",
        "val_dataset   = BraTSDataset(val_paths)"
      ],
      "metadata": {
        "id": "5BBFdZSIIK3N"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect example output\n",
        "sample_img, sample_mask = train_dataset[0]\n",
        "print('Image shape:', sample_img.shape)   # (4, 240, 240)\n",
        "print('Mask shape:', sample_mask.shape)   # (3, 240, 240)\n",
        "print('Image dtype:', sample_img.dtype)\n",
        "print('Mask dtype:', sample_mask.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOviZ7ceaWeO",
        "outputId": "f5a3ceb9-d0a6-4ec9-8f70-78d0964d5828"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape: torch.Size([4, 240, 240])\n",
            "Mask shape: torch.Size([3, 240, 240])\n",
            "Image dtype: torch.float32\n",
            "Mask dtype: torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset Implementation**:\n",
        "\n",
        "Before training, MRI slices must be properly formatted and standardized to ensure consistent numerical representation, improve training stability, and enable efficient batch loading for the U-Net.\n",
        "\n",
        "A custom PyTorch `Dataset` class is defined to load individual 2D slices stored as *.h5* files. Each file contains a 4-channel MRI image (T1, T1Gd, T2, T2-FLAIR) and a 3-channel binary segmentation mask representing tumor subregions.\n",
        "\n",
        "Data is loaded lazily within `__getitem__`, meaning slices are read from disk only when needed. This avoids loading the entire dataset into memory and keeps the pipeline scalable.\n",
        "\n",
        "Images and masks are converted to *float32* for GPU compatibility and reduced memory usage. Each MRI modality channel is also z-score normalized per slice to standardize intensities and stabilize training. This should improve model convergence and help the network learn more effectively. The arrays are then rearranged to channel-first format **(C, H, W)**, which is required by PyTorch convolutional layers. A sample output was generated to inspect it for expected format.\n",
        "\n",
        "This design separates data handling from modeling logic, making the pipeline modular, extensible, and ready for the U-Net baseline."
      ],
      "metadata": {
        "id": "l0VocrLUNuf0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **3c. Create DataLoaders for batching and training.**"
      ],
      "metadata": {
        "id": "tvnlCy3wV4eY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step is to set up data generators to produce iterable batches for training and validation."
      ],
      "metadata": {
        "id": "W35Y_l9VUChm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure batch size based on v1 constrainsts (GPU + slice size)\n",
        "batch_size = 4"
      ],
      "metadata": {
        "id": "WKReuzB6X4Ue"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoaders to handles batching, shuffling, parallel loading, and GPU memory pinning\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,            # shuffle training slices each epoch (ensures SGD sees slices in different order each epoch)\n",
        "    num_workers=2,           # parallel data loading; adjust based on Colab memory / CPU\n",
        "    pin_memory=True          # speeds up transfers to GPU\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,            # maintain deterministic order (i.e., no shuffle) for validation\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")"
      ],
      "metadata": {
        "id": "X881JTQDU5X8"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_images, sample_masks = next(iter(train_loader))\n",
        "print('Batch image shape:', sample_images.shape)  # (B, 4, H, W)\n",
        "print('Batch mask shape: ', sample_masks.shape)   # (B, 3, H, W)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiVjek4qZ6ep",
        "outputId": "170870ec-435f-4718-a071-f58b7dfd337e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch image shape: torch.Size([4, 4, 240, 240])\n",
            "Batch mask shape:  torch.Size([4, 3, 240, 240])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DataLoader Implementation**:\n",
        "\n",
        "With the Dataset class defined, we now set up PyTorch `DataLoader` to efficiently batch and serve slices during training and validation.\n",
        "\n",
        "- **Training DataLoader**: shuffles slices each epoch to provide stochasticity for gradient descent, uses multiple workers for parallel loading, and pins memory for faster GPU transfer.\n",
        "- **Validation DataLoader**: does not shuffle to maintain deterministic evaluation order but still benefits from batching and parallel loading.\n",
        "\n",
        "Inspecting a sample batch image and mask shape confirms that each batch has the expected shape: images **(B, 4, H, W)** and masks **(B, 3, H, W)**. This ensures that data is correctly formatted, normalized, and ready for input into a segmentation model."
      ],
      "metadata": {
        "id": "4SZUAY9fU7PH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 4. Model Architecture ðŸ—ï¸\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "M7HbFiEEWzNv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the data is preprocessed and loaded in batches, the next step is to define the neural network. A **U-Net** will be used as it is specifically designed for image segmentation.\n",
        "\n",
        "- U-Net takes an input image (here, 4 MRI channels) and outputs a segmentation mask (here, 3 channels for necrotic core, edema, enhancing tumor).\n",
        "- It has a **downsampling path** that captures context and an **upsampling path** that recovers spatial details.\n",
        "- The network will learn, for each pixel, whether it belongs to background or one of the tumor sub-regions.\n",
        "\n",
        "This setup allows the model to predict multi-class masks directly from MRI slices."
      ],
      "metadata": {
        "id": "YQl_XrYNXNUD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **4a. Define a baseline U-Net for brain tumor segmentation.**"
      ],
      "metadata": {
        "id": "0v0piAkvchtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LeanUNet(nn.Module):\n",
        "    \"\"\"\n",
        "    U-Net (v1) for multi-class 2D brain tumor segmentation.\n",
        "\n",
        "    Input: 4-channel MRI slice (T1, T1Gd, T2, T2-FLAIR)\n",
        "    Output: 3-channel segmentation mask (Necrotic Core, Edema, Enhancing Tumor)\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    def __init__(self, in_channels=4, out_channels=3, init_features=16):\n",
        "        super(LeanUNet, self).__init__()\n",
        "        features = init_features\n",
        "\n",
        "        ### Encoder (downsampling path)\n",
        "        self.encoder1 = self._conv_block(in_channels, features)\n",
        "        self.pool1    = nn.MaxPool2d(2)\n",
        "\n",
        "        self.encoder2 = self._conv_block(features, features*2)\n",
        "        self.pool2    = nn.MaxPool2d(2)\n",
        "\n",
        "        self.encoder3 = self._conv_block(features*2, features*4)\n",
        "        self.pool3    = nn.MaxPool2d(2)\n",
        "\n",
        "        ### Bottleneck\n",
        "        self.bottleneck = self._conv_block(features*4, features*8)\n",
        "\n",
        "        #### Decoder (upsampling path)\n",
        "        self.upconv3 = nn.ConvTranspose2d(features*8, features*4, kernel_size=2, stride=2)\n",
        "        self.decoder3 = self._conv_block(features*8, features*4)\n",
        "\n",
        "        self.upconv2 = nn.ConvTranspose2d(features*4, features*2, kernel_size=2, stride=2)\n",
        "        self.decoder2 = self._conv_block(features*4, features*2)\n",
        "\n",
        "        self.upconv1 = nn.ConvTranspose2d(features*2, features, kernel_size=2, stride=2)\n",
        "        self.decoder1 = self._conv_block(features*2, features)\n",
        "\n",
        "        ### Output layer\n",
        "        self.conv_final = nn.Conv2d(features, out_channels, kernel_size=1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        ### Encoder forward pass\n",
        "        enc1 = self.encoder1(x)\n",
        "        enc2 = self.encoder2(self.pool1(enc1))\n",
        "        enc3 = self.encoder3(self.pool2(enc2))\n",
        "\n",
        "        ### Bottleneck\n",
        "        bottleneck = self.bottleneck(self.pool3(enc3))\n",
        "\n",
        "        ### Decoder forward pass with skip connections\n",
        "        dec3 = self.upconv3(bottleneck)  # upsample\n",
        "        dec3 = torch.cat((dec3, enc3), dim=1)  # concatenate skip connection from encoder\n",
        "        dec3 = self.decoder3(dec3)\n",
        "\n",
        "        dec2 = self.upconv2(dec3)\n",
        "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
        "        dec2 = self.decoder2(dec2)\n",
        "\n",
        "        dec1 = self.upconv1(dec2)\n",
        "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
        "        dec1 = self.decoder1(dec1)\n",
        "\n",
        "        ### Output\n",
        "        return self.conv_final(dec1)\n",
        "\n",
        "\n",
        "    ### 2-conv block\n",
        "    def _conv_block(self, in_channels, out_channels):\n",
        "        \"\"\"\n",
        "        Standard double-convolution block:\n",
        "            Conv2d -> ReLU -> Conv2d -> ReLU\n",
        "        \"\"\"\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )"
      ],
      "metadata": {
        "id": "dEJigYnxdKbT"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define computation mode\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Device: ', device)\n",
        "\n",
        "# Instantiate model\n",
        "model = LeanUNet().to(device)\n",
        "# print(model)\n",
        "\n",
        "# Check output shape for an example batch (will be consolidated later as unit test modules)\n",
        "ex_input = torch.randn(2, 4, 240, 240).to(device)\n",
        "ex_output = model(ex_input)\n",
        "print('Example output shape:', ex_output.shape)  # Expected: (2, 3, 240, 240)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvJ-zKoPdNoM",
        "outputId": "0590839d-e2d7-4f03-ec7b-3fa3bd9578fc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device:  cuda\n",
            "Example output shape: torch.Size([2, 3, 240, 240])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**U-Net Architecture**:\n",
        "\n",
        "- **DoubleConv block**: Two consecutive convolution layers with ReLU activation capture local features efficiently.  \n",
        "- **Downsampling path**: `DoubleConv + MaxPool` layers reduce spatial dimensions while increasing feature depth, learning contextual information.  \n",
        "- **Bottleneck**: The deepest layer with the highest feature dimension, capturing the most abstract representation of the input.  \n",
        "- **Upsampling path**: Transposed convolutions increase spatial resolution, and skip connections concatenate features from the corresponding downsampling layers to recover fine details.  \n",
        "- **Output layer**: A 1Ã—1 convolution maps features to `out_ch` channels (3 tumor classes).\n",
        "\n",
        "**Input / Output**:\n",
        "\n",
        "- **Input**: (C=4, H=240, W=240) MRI slice with four modalities (T1, T1Gd, T2, T2-FLAIR).  \n",
        "- **Output**: (C=3, H=240, W=240) multi-class segmentation mask, one channel per tumor sub-region.\n",
        "\n",
        "This design allows the model to predict spatially precise tumor regions while leveraging both global context and local details.\n"
      ],
      "metadata": {
        "id": "Tu_9HsviX3uT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **4b. Specify loss function for multi-class segmentation.**\n"
      ],
      "metadata": {
        "id": "YfSvAVCWcma7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DiceLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Computes Dice Loss for multi-channel segmentation.\n",
        "    Handles multi-label targets with one channel per class.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, smooth=1e-6):\n",
        "        super(DiceLoss, self).__init__()\n",
        "        self.smooth = smooth\n",
        "\n",
        "    def forward(self, preds, targets):\n",
        "        # Predictions and Targets: (B, C, H, W)\n",
        "        preds = torch.sigmoid(preds)  # Ensure outputs in [0,1]\n",
        "        intersection = (preds * targets).sum(dim=(2,3))\n",
        "        union = preds.sum(dim=(2,3)) + targets.sum(dim=(2,3))\n",
        "        dice = (2. * intersection + self.smooth) / (union + self.smooth)\n",
        "        return 1 - dice.mean()  # 1 - mean Dice across batch and channels"
      ],
      "metadata": {
        "id": "79d9NdE0oB_1"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate loss function\n",
        "criterion = DiceLoss()\n",
        "\n",
        "# Inspect with sample tensors (will be consolidated later as unit test modules)\n",
        "ex_preds = torch.randn(2, 3, 240, 240).to(device)\n",
        "ex_targets = torch.randint(0, 2, (2, 3, 240, 240)).float().to(device)\n",
        "loss = criterion(ex_preds, ex_targets)\n",
        "print('Sample Dice loss: ', loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCdKeZOgoCBN",
        "outputId": "7d6bb292-d1a6-4258-b533-56a6faf16472"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Dice loss:  0.49946802854537964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loss Function for Multi-Class Segmentation**:\n",
        "\n",
        "Brain tumor segmentation exhibits extreme class imbalance, with most pixels belonging to healthy tissue / background. Dice Loss is well-suited for this scenario, as it directly measures the overlap between predicted and ground-truth masks.\n",
        "\n",
        "- **Multi-channel Dice Loss**: Computed independently per tumor sub-region, then averaged.  \n",
        "- **Sigmoid activation**: Converts raw logits to probabilities in [0,1] for each channel.  \n",
        "- **Smooth term**: Prevents division by zero when a class is absent in a slice.\n",
        "\n",
        "This ensures the model learns to capture small, clinically relevant tumor regions rather than being dominated by background pixels. Combining Dice Loss with standard binary cross-entropy can also stabilize training for future versions."
      ],
      "metadata": {
        "id": "RvIj41S-okTu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **4c. Configure optimizer and learning rate scheduler.**\n"
      ],
      "metadata": {
        "id": "Mivvj_wGcmeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure Adam optimizer (adaptive learning rates, fast convergence)\n",
        "learning_rate = 1e-3\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "L6UmWgVEqiEw"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up LR scheduler to reduce LR if validation Dice plateaus (help convergences)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='max',           # maximize validation Dice\n",
        "    factor=0.5,           # reduce LR by half\n",
        "    patience=3,           # wait 3 epochs without improvement\n",
        ")"
      ],
      "metadata": {
        "id": "1b2zwCHmqiKK"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Optimizer parameters count: ', sum(p.numel() for p in model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLdlU0cBrY7n",
        "outputId": "4e7cfae2-236c-4a5e-b072-2bbc3daf8fb7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizer parameters count:  482915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimizer and Learning Rate Scheduler**:\n",
        "\n",
        "- **Optimizer**: Adam is chosen for its adaptive learning rate capabilities and fast convergence, which is suitable for small baseline datasets.  \n",
        "- **Learning rate**: Initialized at 1e-3, balancing stability and speed of convergence.  \n",
        "- **Scheduler**: `ReduceLROnPlateau` monitors validation Dice; if no improvement occurs for 3 epochs, the learning rate is halved to encourage further optimization.\n",
        "\n",
        "This setup provides a flexible and efficient optimization loop for training the baseline U-Net without manual LR tuning."
      ],
      "metadata": {
        "id": "sS8pZn0ersO0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **4d. Define validation Dice evaluation.**\n"
      ],
      "metadata": {
        "id": "-VjdEKFxvAuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_dice(preds, targets, threshold=0.5, smooth=1e-6):\n",
        "    \"\"\"\n",
        "    Compute per-channel and mean Dice coefficient for multi-label masks.\n",
        "\n",
        "    Args:\n",
        "        preds (torch.Tensor): Model outputs (B, C, H, W) raw logits.\n",
        "        targets (torch.Tensor): Ground-truth masks (B, C, H, W) in {0,1}.\n",
        "        threshold (float): Sigmoid threshold to binarize predictions.\n",
        "        smooth (float): Small value to avoid division by zero.\n",
        "\n",
        "    Returns:\n",
        "        dice_per_channel (list of float): Dice for each mask channel.\n",
        "        mean_dice (float): Average Dice across channels.\n",
        "    \"\"\"\n",
        "\n",
        "    # Apply sigmoid and binarize\n",
        "    preds = torch.sigmoid(preds) > threshold\n",
        "\n",
        "    # Flatten spatial dimensions\n",
        "    preds_flat = preds.view(preds.size(0), preds.size(1), -1).float()\n",
        "    targets_flat = targets.view(targets.size(0), targets.size(1), -1).float()\n",
        "\n",
        "    # Compute intersection and union per channel\n",
        "    intersection = (preds_flat * targets_flat).sum(dim=2)\n",
        "    union = preds_flat.sum(dim=2) + targets_flat.sum(dim=2)\n",
        "\n",
        "    # Dice per channel for each sample\n",
        "    dice = (2 * intersection + smooth) / (union + smooth)\n",
        "\n",
        "    # Average over batch\n",
        "    dice_per_channel = dice.mean(dim=0).cpu().tolist()\n",
        "    mean_dice = dice.mean().item()\n",
        "\n",
        "    return dice_per_channel, mean_dice"
      ],
      "metadata": {
        "id": "w-W6m7k-vGkr"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Validation Dice Evaluation**:\n",
        "\n",
        "This function computes Dice scores for multi-label segmentation:\n",
        "\n",
        "- **Per-channel Dice**: Calculates Dice for each tumor sub-region independently.  \n",
        "- **Mean Dice**: Average across all channels to summarize overall performance.  \n",
        "- **Binarization**: Predictions are converted from raw logits to 0/1 using a sigmoid threshold (default 0.5).  \n",
        "- **Batch-wise averaging**: Dice is first computed per slice, then averaged over the batch.\n",
        "\n",
        "This helper allows efficient evaluation of model performance on the validation set at the end of each epoch or after training without adding significant compute overhead."
      ],
      "metadata": {
        "id": "bssQsIFfvMG9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **4e. Set up remaining training parameters.**\n"
      ],
      "metadata": {
        "id": "2AtZU4RpcmhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training parameters\n",
        "num_epochs = 50\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Move model to device (GPU or CPU)\n",
        "model.to(device)\n",
        "\n",
        "print(f'Training is set up to run on {device} for {num_epochs} epochs with batch size {batch_size}.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WeofiZNsOUi",
        "outputId": "fc866c3d-3b47-4a1d-c0e1-ed527f7b1e4a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training is set up to run on cuda for 8 epochs with batch size 4.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The baseline U-Net, loss function, optimizer, scheduler, and training parameters are now fully defined. The model is moved to GPU if available for faster computation. **DiceLoss** handles each mask channel as an independent binary label, making it ideal for multi-label segmentation. The **Adam optimizer** provides adaptive learning rates for efficient convergence. `num_epochs` sets how many times the dataset is seen during training, and `batch_size` controls memory usage and gradient stability. With all components in place, the model is ready for training in the next section."
      ],
      "metadata": {
        "id": "89huX2KWbxty"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 5. Model Training ðŸ¤–\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "aKEolpmAd0B3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up path for checkpoint saves\n",
        "drive_models_path = '/content/drive/MyDrive/modelsv1'\n",
        "os.makedirs(drive_models_path, exist_ok=True)\n",
        "\n",
        "print('Checkpoints will be saved to: ', drive_models_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0Gk2m5QxU21",
        "outputId": "5da2a0eb-5dba-4403-d757-4b4fd4911aa5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoints will be saved to:  /content/drive/MyDrive/modelsv1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "For each batch, the process is as follows:\n",
        "\n",
        "Feed MRI slices into the model --> Compute predictions --> Calculate loss --> Backpropagate --> Update weights.  The loss will be tracked over epochs to see if the model is learning."
      ],
      "metadata": {
        "id": "fZ4WLSOmaqf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, num_epochs):  # num_epochs+1*\n",
        "\n",
        "\n",
        "    # -------------------------------\n",
        "    # Training Phase\n",
        "    # -------------------------------\n",
        "    model.train()       # Enable gradients and training behaviors\n",
        "    train_loss = 0.0    # Accumulate loss over epoch\n",
        "\n",
        "    for images, masks in tqdm(train_loader, desc=f'Epoch {epoch} [Train]'):\n",
        "        images = images.to(device)\n",
        "        masks = masks.to(device)\n",
        "\n",
        "        optimizer.zero_grad()            # Reset gradients\n",
        "        outputs = model(images)          # Forward pass\n",
        "        loss = criterion(outputs, masks) # Dice loss\n",
        "        loss.backward()                  # Backpropagate\n",
        "        optimizer.step()                 # Update weights\n",
        "\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "\n",
        "    train_loss /= len(train_loader.dataset)  # Average over all slices\n",
        "\n",
        "\n",
        "    # -------------------------\n",
        "    # Checkpoint Save (in case of Colab timeouts)\n",
        "    # -------------------------\n",
        "    checkpoint_path = os.path.join(drive_models_path, f'v1_epoch_{epoch}.pt')\n",
        "\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': train_loss,\n",
        "    }, checkpoint_path)\n",
        "\n",
        "    print(f'Checkpoint saved: {checkpoint_path}')\n",
        "\n",
        "\n",
        "    # -------------------------------\n",
        "    # Validation Phase\n",
        "    # -------------------------------\n",
        "    # Set model to evaluation mode (disables training behaviors, dropout, batchnorm updates)\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    dice_per_channel_accum = []\n",
        "\n",
        "    # Disable gradient computation for validation\n",
        "    with torch.no_grad():\n",
        "        for images, masks in tqdm(val_loader, desc=f'Epoch {epoch} [Val]'):\n",
        "            images = images.to(device)\n",
        "            masks = masks.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, masks)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "\n",
        "            # Compute Dice per channel for this batch\n",
        "            dice_ch, mean_dice = compute_dice(outputs, masks)\n",
        "            dice_per_channel_accum.append(dice_ch)\n",
        "\n",
        "    # Average validation metrics across all batches\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    dice_per_channel_avg = [sum(col)/len(col) for col in zip(*dice_per_channel_accum)]\n",
        "    mean_dice_avg = sum(dice_per_channel_avg)/len(dice_per_channel_avg)\n",
        "\n",
        "    # -------------------------------\n",
        "    # Scheduler Step\n",
        "    # -------------------------------\n",
        "    scheduler.step(mean_dice_avg)  # Adjust LR based on validation Dice\n",
        "\n",
        "    # -------------------------------\n",
        "    # Epoch Summary\n",
        "    # -------------------------------\n",
        "\n",
        "    print(f'Epoch [{epoch}/{num_epochs}] | '\n",
        "          f'Train Loss: {train_loss:.4f} | '\n",
        "          f'Val Loss: {val_loss:.4f} | '\n",
        "          f'Mean Dice: {mean_dice_avg:.4f} | '\n",
        "          f'Dice per channel: {dice_per_channel_avg}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiTCiVpxvxp7",
        "outputId": "4c80d9c5-8cd6-41c8-9dbd-af7643244097"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:06<00:00, 17.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_1.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 24.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/8] | Train Loss: 0.8734 | Val Loss: 0.8296 | Mean Dice: 0.3083 | Dice per channel: [0.21273225898345652, 0.316785276442985, 0.39523367972008566]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:05<00:00, 22.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_2.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 25.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/8] | Train Loss: 0.8657 | Val Loss: 0.8253 | Mean Dice: 0.4564 | Dice per channel: [0.22706519526564406, 0.4846369223360314, 0.6575625609388689]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:06<00:00, 17.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_3.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 23.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/8] | Train Loss: 0.8604 | Val Loss: 0.8390 | Mean Dice: 0.4294 | Dice per channel: [0.21466430628204564, 0.41258106191227556, 0.6608511547427282]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:05<00:00, 20.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_4.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 22.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/8] | Train Loss: 0.8593 | Val Loss: 0.8458 | Mean Dice: 0.3950 | Dice per channel: [0.22671341870155481, 0.42111877620114796, 0.5373108620729475]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:06<00:00, 17.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_5.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 24.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/8] | Train Loss: 0.8529 | Val Loss: 0.8312 | Mean Dice: 0.3224 | Dice per channel: [0.21208288314012586, 0.37059491225649605, 0.38441269729144534]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:05<00:00, 22.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_6.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 24.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/8] | Train Loss: 0.8505 | Val Loss: 0.7940 | Mean Dice: 0.4708 | Dice per channel: [0.23043876626092874, 0.4369352961968282, 0.7450501355919977]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:06<00:00, 17.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_7.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 25.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/8] | Train Loss: 0.8479 | Val Loss: 0.8381 | Mean Dice: 0.5028 | Dice per channel: [0.30878568293624087, 0.5016806517052023, 0.6978667075424149]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:05<00:00, 22.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_8.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:02<00:00, 17.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/8] | Train Loss: 0.8397 | Val Loss: 0.8146 | Mean Dice: 0.4338 | Dice per channel: [0.23050497472136414, 0.35467334452663063, 0.7160810387141934]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:06<00:00, 19.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_9.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 25.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/8] | Train Loss: 0.8340 | Val Loss: 0.8153 | Mean Dice: 0.4415 | Dice per channel: [0.24893599324007104, 0.37367897341363376, 0.701925099792831]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:05<00:00, 22.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_10.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:02<00:00, 15.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/8] | Train Loss: 0.8376 | Val Loss: 0.8186 | Mean Dice: 0.4224 | Dice per channel: [0.2330560401875173, 0.3724450478268295, 0.6616846194375362]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:05<00:00, 20.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_11.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 25.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11/8] | Train Loss: 0.8331 | Val Loss: 0.8532 | Mean Dice: 0.2986 | Dice per channel: [0.21571045855823784, 0.3200969471416493, 0.360029041591192]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:05<00:00, 19.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_12.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:02<00:00, 17.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12/8] | Train Loss: 0.8260 | Val Loss: 0.8032 | Mean Dice: 0.4708 | Dice per channel: [0.32974280140568507, 0.39590450769139585, 0.6868412354206886]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:05<00:00, 21.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_13.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 25.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13/8] | Train Loss: 0.8201 | Val Loss: 0.7939 | Mean Dice: 0.4867 | Dice per channel: [0.36857469115758335, 0.42036222185358196, 0.6710195694640125]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:06<00:00, 18.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_14.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 22.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14/8] | Train Loss: 0.8165 | Val Loss: 0.8982 | Mean Dice: 0.4786 | Dice per channel: [0.2825758184889871, 0.5267587765123637, 0.6264269846233212]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:05<00:00, 22.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_15.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 25.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/8] | Train Loss: 0.8138 | Val Loss: 0.8487 | Mean Dice: 0.4100 | Dice per channel: [0.40909319857171217, 0.3193979984071351, 0.5013919782040945]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:06<00:00, 17.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_16.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 25.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [16/8] | Train Loss: 0.8072 | Val Loss: 0.8120 | Mean Dice: 0.4583 | Dice per channel: [0.2824817657297188, 0.43097861884715755, 0.6614391680437374]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:05<00:00, 23.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_17.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 23.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [17/8] | Train Loss: 0.8024 | Val Loss: 0.8697 | Mean Dice: 0.4626 | Dice per channel: [0.3202865348242498, 0.5013679864534618, 0.5661865984960192]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:06<00:00, 17.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_18.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 25.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [18/8] | Train Loss: 0.7994 | Val Loss: 0.8205 | Mean Dice: 0.4861 | Dice per channel: [0.38027341499747785, 0.4441040371636005, 0.6339202628480944]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:05<00:00, 22.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_19.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 25.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [19/8] | Train Loss: 0.7982 | Val Loss: 0.8451 | Mean Dice: 0.4273 | Dice per channel: [0.2683192573912475, 0.4164601278269097, 0.5970431474048249]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:06<00:00, 17.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_20.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 25.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/8] | Train Loss: 0.7967 | Val Loss: 0.8339 | Mean Dice: 0.5044 | Dice per channel: [0.4155762052286815, 0.45079735936628595, 0.6468384617247461]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:05<00:00, 23.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_21.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 25.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [21/8] | Train Loss: 0.7952 | Val Loss: 0.8326 | Mean Dice: 0.5332 | Dice per channel: [0.4693994732118391, 0.4734696049995084, 0.6566085986728353]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:06<00:00, 17.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_22.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 25.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [22/8] | Train Loss: 0.7946 | Val Loss: 0.8127 | Mean Dice: 0.4893 | Dice per channel: [0.35201388581843945, 0.4543470816107453, 0.6615833800264929]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:04<00:00, 23.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_23.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 21.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [23/8] | Train Loss: 0.7941 | Val Loss: 0.8526 | Mean Dice: 0.5152 | Dice per channel: [0.4523241837812158, 0.4847227052861135, 0.6085677876165985]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:06<00:00, 18.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_24.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 24.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [24/8] | Train Loss: 0.7920 | Val Loss: 0.8214 | Mean Dice: 0.4839 | Dice per channel: [0.3782276300752577, 0.43761770811137823, 0.6358728178473809]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:05<00:00, 22.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_25.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:02<00:00, 18.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [25/8] | Train Loss: 0.7923 | Val Loss: 0.8326 | Mean Dice: 0.4401 | Dice per channel: [0.2946945058932281, 0.43894484746288326, 0.5865674726550664]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:06<00:00, 18.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_26.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 25.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [26/8] | Train Loss: 0.7906 | Val Loss: 0.8297 | Mean Dice: 0.4579 | Dice per channel: [0.3161230450708251, 0.4339177057120276, 0.6238068143655181]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:05<00:00, 22.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_27.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:02<00:00, 14.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [27/8] | Train Loss: 0.7900 | Val Loss: 0.8422 | Mean Dice: 0.4728 | Dice per channel: [0.36601951482243883, 0.4517242786694207, 0.6005784642322771]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:05<00:00, 21.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_28.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 26.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [28/8] | Train Loss: 0.7890 | Val Loss: 0.8197 | Mean Dice: 0.4661 | Dice per channel: [0.31161486627320567, 0.4381369598371895, 0.6484544405309135]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:05<00:00, 20.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_29.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:02<00:00, 15.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [29/8] | Train Loss: 0.7904 | Val Loss: 0.8424 | Mean Dice: 0.4786 | Dice per channel: [0.3896331669017656, 0.44781940066486153, 0.598407979648272]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:05<00:00, 22.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_30.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 25.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [30/8] | Train Loss: 0.7892 | Val Loss: 0.8465 | Mean Dice: 0.4862 | Dice per channel: [0.4044108306404154, 0.4717769497033535, 0.5824152744301436]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:06<00:00, 18.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_31.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:02<00:00, 18.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [31/8] | Train Loss: 0.7895 | Val Loss: 0.8229 | Mean Dice: 0.4990 | Dice per channel: [0.4195609180309478, 0.44299786031492316, 0.6345570097464432]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:05<00:00, 22.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_32.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 25.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [32/8] | Train Loss: 0.7885 | Val Loss: 0.8332 | Mean Dice: 0.5156 | Dice per channel: [0.4489397437457853, 0.4771756357048608, 0.6206832805726594]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:06<00:00, 17.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_33.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 23.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [33/8] | Train Loss: 0.7879 | Val Loss: 0.8285 | Mean Dice: 0.5312 | Dice per channel: [0.47526596249735237, 0.4729613744920256, 0.6455034101460536]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:05<00:00, 22.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_34.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 26.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [34/8] | Train Loss: 0.7878 | Val Loss: 0.8294 | Mean Dice: 0.4799 | Dice per channel: [0.3769294294926092, 0.4383660511053371, 0.624286850961802]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:06<00:00, 17.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_35.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 25.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [35/8] | Train Loss: 0.7883 | Val Loss: 0.8254 | Mean Dice: 0.5239 | Dice per channel: [0.47744154540051453, 0.46495101852784315, 0.6292229327088743]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:05<00:00, 22.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_36.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 26.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [36/8] | Train Loss: 0.7893 | Val Loss: 0.8217 | Mean Dice: 0.5106 | Dice per channel: [0.4455362480939779, 0.44939198549469156, 0.6367474272122756]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:06<00:00, 17.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_37.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 25.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [37/8] | Train Loss: 0.7881 | Val Loss: 0.8436 | Mean Dice: 0.4863 | Dice per channel: [0.394205163486704, 0.4583966617048142, 0.6063451617698288]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:05<00:00, 22.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_38.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 26.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [38/8] | Train Loss: 0.7882 | Val Loss: 0.8368 | Mean Dice: 0.5355 | Dice per channel: [0.4790488645772277, 0.4782677282239619, 0.6491274835951055]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:06<00:00, 17.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_39.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 26.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [39/8] | Train Loss: 0.7875 | Val Loss: 0.8369 | Mean Dice: 0.5269 | Dice per channel: [0.47606888781580153, 0.4722772358821847, 0.6322685428750567]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:05<00:00, 23.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_40.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 25.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [40/8] | Train Loss: 0.7877 | Val Loss: 0.8161 | Mean Dice: 0.4888 | Dice per channel: [0.3833661706972277, 0.4424189856255474, 0.6405005274914157]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 41 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:06<00:00, 17.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_41.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 41 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 26.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [41/8] | Train Loss: 0.7882 | Val Loss: 0.8484 | Mean Dice: 0.5111 | Dice per channel: [0.4270894591270842, 0.46950763849094784, 0.6368467492207627]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 42 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:05<00:00, 23.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_42.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 42 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 23.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [42/8] | Train Loss: 0.7882 | Val Loss: 0.8290 | Mean Dice: 0.4927 | Dice per channel: [0.41363304055424865, 0.44090971891869973, 0.6235713940676779]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 43 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:06<00:00, 18.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_43.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 43 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 25.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [43/8] | Train Loss: 0.7883 | Val Loss: 0.8405 | Mean Dice: 0.5233 | Dice per channel: [0.46740204434546573, 0.48789232473131816, 0.6147417007561068]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 44 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:05<00:00, 23.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_44.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 44 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 19.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [44/8] | Train Loss: 0.7878 | Val Loss: 0.8438 | Mean Dice: 0.5416 | Dice per channel: [0.5001843433682615, 0.4773910953697974, 0.6473022907356241]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 45 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:06<00:00, 18.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_45.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 45 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 26.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [45/8] | Train Loss: 0.7881 | Val Loss: 0.8353 | Mean Dice: 0.5413 | Dice per channel: [0.5127993506853373, 0.48113021034708897, 0.6298287678874736]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 46 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:05<00:00, 23.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_46.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 46 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:02<00:00, 15.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [46/8] | Train Loss: 0.7884 | Val Loss: 0.8446 | Mean Dice: 0.5218 | Dice per channel: [0.4692593988581059, 0.490445056536605, 0.6057026287688357]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 47 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:05<00:00, 19.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_47.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 47 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 26.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [47/8] | Train Loss: 0.7881 | Val Loss: 0.8215 | Mean Dice: 0.5021 | Dice per channel: [0.4198409014714806, 0.4558934668179087, 0.6305134104771611]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 48 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:05<00:00, 23.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_48.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 48 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:02<00:00, 15.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [48/8] | Train Loss: 0.7869 | Val Loss: 0.8274 | Mean Dice: 0.5325 | Dice per channel: [0.48098334522082153, 0.4818520928453866, 0.6346212610801387]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 49 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 117/117 [00:05<00:00, 20.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: /content/drive/MyDrive/modelsv1/v1_epoch_49.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 49 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 25.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [49/8] | Train Loss: 0.7878 | Val Loss: 0.8359 | Mean Dice: 0.4966 | Dice per channel: [0.4283741005923439, 0.4566021029487874, 0.6048947491646743]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This loop iterates over epochs, updating the model on training slices and evaluating its performance on the validation set:\n",
        "\n",
        "- **Training phase**: Computes Dice loss, backpropagates, and updates weights via Adam optimizer.  \n",
        "- **Validation phase**: Disables gradients and computes both loss and Dice metrics for each tumor sub-region using the evaluation helper function from the previous section.  \n",
        "- **Per-channel Dice**: Monitors performance on necrotic core, edema, and enhancing tumor independently.  \n",
        "- **Mean Dice**: Average of all channels provides a single performance summary.  \n",
        "- **Scheduler step**: Optionally reduces learning rate if validation Dice plateaus.  \n",
        "- **Epoch summary**: Prints training loss, validation loss, mean Dice, and per-channel Dice for monitoring progress.\n",
        "\n",
        "This setup ensures the baseline model is trained efficiently while keeping track of clinically relevant metrics despite extreme class imbalance."
      ],
      "metadata": {
        "id": "Bfh3l8RzvyBF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 6. Model Evaluation ðŸ“‹\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "duUvpkI58M_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "final_val_loss = 0.0                     # Accumulate total validation loss\n",
        "dice_per_channel_accum = []              # Store per-batch Dice scores\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    # Iterate through validation DataLoader\n",
        "    for images, masks in tqdm(val_loader, desc='Final Validation'):\n",
        "\n",
        "        # Move data to same device as model (GPU if available)\n",
        "        images = images.to(device)\n",
        "        masks = masks.to(device)\n",
        "\n",
        "        # Forward pass only (no backpropagation)\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Compute validation loss using DiceLoss\n",
        "        loss = criterion(outputs, masks)\n",
        "\n",
        "        # Accumulate loss weighted by batch size\n",
        "        final_val_loss += loss.item() * images.size(0)\n",
        "\n",
        "        # Compute Dice per channel for this batch\n",
        "        # compute_dice applies sigmoid + threshold internally\n",
        "        dice_ch, _ = compute_dice(outputs, masks)\n",
        "\n",
        "        # Store per-channel Dice values\n",
        "        dice_per_channel_accum.append(dice_ch)\n",
        "\n",
        "# Average validation loss over total number of slices\n",
        "final_val_loss /= len(val_loader.dataset)\n",
        "\n",
        "# Average Dice per channel across all batches\n",
        "dice_per_channel_avg = [\n",
        "    sum(col) / len(col) for col in zip(*dice_per_channel_accum)\n",
        "]\n",
        "\n",
        "# Compute overall mean Dice across channels\n",
        "mean_dice_avg = sum(dice_per_channel_avg) / len(dice_per_channel_avg)\n",
        "\n",
        "# Print final evaluation metrics\n",
        "print('----- Final Validation Results -----')\n",
        "print(f'Validation Loss: {final_val_loss:.4f}')\n",
        "print(f'Mean Dice: {mean_dice_avg:.4f}')\n",
        "print(f'Dice per channel: {dice_per_channel_avg}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vIaiMwXvxsZ",
        "outputId": "88bfeb74-dc2c-4f50-ec24-591de12426aa"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Final Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:01<00:00, 25.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- Final Validation Results -----\n",
            "Validation Loss: 0.8359\n",
            "Mean Dice: 0.4966\n",
            "Dice per channel: [0.4283741005923439, 0.4566021029487874, 0.6048947491646743]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Final Validation Metrics**:\n",
        "\n",
        "After ~50 epochs of training, the model is evaluated on the held-out validation patient. The model achieves a validation loss of 0.8359 and a mean Dice score of 0.4966 on the held-out validation set.\n",
        "\n",
        "Dice performance varies across channels:\n",
        "\n",
        "- **NEC/NET**: 0.4284\n",
        "- **ED**: 0.4566\n",
        "- **ET**: 0.6049\n",
        "\n",
        "This indicates the model is learning meaningful spatial structure, with the strongest performance on the third class. However, overall Dice remains around 0.5, suggesting segmentation quality is moderate and definitely can be improved in future versions. As a baseline U-Net trained on heavily downscaled slices, this serves as a functional reference point."
      ],
      "metadata": {
        "id": "W243oXUl8qUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select a specific validation slice\n",
        "slice_index = 33\n",
        "\n",
        "image, mask = val_dataset[slice_index]\n",
        "\n",
        "# Add batch dimension (model expects B,C,H,W)\n",
        "image = image.unsqueeze(0).to(device)\n",
        "mask = mask.unsqueeze(0).to(device)\n",
        "\n",
        "# Set model to eval mode\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(image)\n",
        "    probs = torch.sigmoid(output)\n",
        "    pred = (probs > 0.5).float()\n",
        "\n",
        "# Move everything to CPU for plotting\n",
        "image = image.cpu()\n",
        "mask = mask.cpu()\n",
        "pred = pred.cpu()\n",
        "\n",
        "# Remove batch dimension for plotting\n",
        "image = image[0]\n",
        "mask = mask[0]\n",
        "pred = pred[0]\n",
        "\n",
        "# Set up figure\n",
        "fig, axes = plt.subplots(2, 3, figsize=(10, 10))\n",
        "\n",
        "# Iterable colors and plot titles\n",
        "channel_colors = ['maroon', 'yellowgreen', 'red']\n",
        "actual_titles = ['Annotated NEC/NET', 'Annotated ED', 'Annotated ET']\n",
        "pred_titles = ['Predicted NEC/NET', 'Predicted ED', 'Predicted ET']\n",
        "\n",
        "# Ground Truth\n",
        "for c in range(3):\n",
        "    annotated_cmap = ListedColormap(['black', channel_colors[c]])\n",
        "    axes[0, c].imshow(mask[c], cmap=annotated_cmap, vmin=0, vmax=1)\n",
        "    axes[0, c].set_title(actual_titles[c])\n",
        "    axes[0, c].axis('off')\n",
        "\n",
        "# Predictions\n",
        "for c in range(3):\n",
        "    pred_cmap = ListedColormap(['black', channel_colors[c]])\n",
        "    axes[1, c].imshow(pred[c], cmap=pred_cmap, vmin=0, vmax=1)\n",
        "    axes[1, c].set_title(pred_titles[c])\n",
        "    axes[1, c].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        },
        "id": "v59Ct6Cv8byZ",
        "outputId": "e57781d3-ea3b-43b8-f351-7cb9a256489e"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Conclusions\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Ex0bWjWfFrDs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This baseline version implemented a multi-class brain tumor segmentation pipeline trained with Dice loss, achieving a mean validation Dice score of 0.4966. Performance varied across tumor subregions, with enhancing tumor (ET) segmented more reliably than necrotic and edema regionsâ€”an expected pattern given class imbalance and irregular boundaries.\n",
        "\n",
        "Visual evaluation revealed extensive slice-to-slice variability. Some predictions exceeded what the average Dice score suggests, while others fell short, reinforcing the need to assess both quantitative and qualitative results in medical imaging tasks.\n",
        "\n",
        "Several improvements could strengthen this baseline for future versions:\n",
        "\n",
        "- **Class imbalance handling:** weighted Dice, hybrid Dice + BCE, focal loss, or foreground-aware sampling\n",
        "- **3D context modeling:** 2.5D inputs or full 3D U-Net architectures\n",
        "- **Stronger augmentation:** elastic deformations, affine transforms, intensity shifts\n",
        "- **Architectural upgrades:** attention mechanisms, residual backbones, pretrained encoders\n",
        "- **Post-processing:** connected-component filtering to reduce false positives\n",
        "- **Cross-validation:** more reliable performance estimation across folds\n",
        "\n",
        "Overall, this notebook establishes a clean, reproducible baseline with a solid training and evaluation pipeline. While performance is modest, the structure is robust and ready for improved iterations."
      ],
      "metadata": {
        "id": "8TXeW2b8FrGn"
      }
    }
  ]
}
